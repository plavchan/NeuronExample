{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Single Neuron Neural Network, borrowed heavily/verbatim from: https://www.kdnuggets.com/2018/10/simple-neural-network-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # the only library needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the class and its functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self):\n",
    "        # seeding for random number generation\n",
    "        np.random.seed(1)\n",
    "        d=3        \n",
    "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
    "        self.synaptic_weights = 2 * np.random.random((d, 1)) - 1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        #applying the sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        #computing derivative to the Sigmoid function\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "        \n",
    "        #training the model to make accurate predictions while adjusting weights continually\n",
    "        for iteration in range(training_iterations):\n",
    "            #siphon the training data via  the neuron\n",
    "            output = self.think(training_inputs)\n",
    "\n",
    "            #computing error rate for back-propagation\n",
    "            error = training_outputs - output\n",
    "            \n",
    "            #performing weight adjustments\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            self.synaptic_weights += adjustments\n",
    "\n",
    "    def think(self, inputs):\n",
    "        #passing the inputs via the neuron to get output   \n",
    "        #converting values to floats\n",
    "        \n",
    "        inputs = inputs.astype(float)\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the neuron class\n",
    "neural_network = NeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Randomly Generated Weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Beginning Randomly Generated Weights: \")\n",
    "print(neural_network.synaptic_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data consisting of 4 examples--3 input values and 1 output\n",
    "training_inputs = np.array([[0,0,1],\n",
    "                            [1,1,1],\n",
    "                            [1,0,1],\n",
    "                            [0,1,1]])\n",
    "\n",
    "training_outputs = np.array([[0,1,1,0]]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training taking place\n",
    "neural_network.train(training_inputs, training_outputs, 15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending Weights After Training: \n",
      "[[10.08740896]\n",
      " [-0.20695366]\n",
      " [-4.83757835]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ending Weights After Training: \")\n",
    "print(neural_network.synaptic_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_one = \"1\"\n",
    "user_input_two = \"0\"\n",
    "user_input_three = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering New Situation:  1 0 0\n",
      "New Output data: \n",
      "[0.9999584]\n",
      "Wow, we did it!\n"
     ]
    }
   ],
   "source": [
    "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
    "    print(\"New Output data: \")\n",
    "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
    "    print(\"Wow, we did it!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to create a simple neural network.\n",
    "\n",
    "The neuron began by allocating itself some random weights. Thereafter, it trained itself using the training examples.\n",
    "\n",
    "Consequently, if it was presented with a new situation [1,0,0], it gave the value of 0.9999584.\n",
    "\n",
    "You remember that the correct answer we wanted was 1?\n",
    "\n",
    "Then, that’s very close—considering that the Sigmoid function outputs values between 0 and 1.\n",
    "\n",
    "Of course, we only used one neuron network to carry out the simple task. What if we connected several thousands of these artificial neural networks together? Could we possibly mimic how the human mind works 100%?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
